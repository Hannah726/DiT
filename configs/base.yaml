# MDLM Base Configuration

# Data settings
data:
  data_dir: "/home/users/nus/e1582377/RawDiff/data/processed_12"
  use_reduced_vocab: true  # Use reduced vocab vs full
  use_continuous_time: false  # Start with discrete time
  num_workers: 4

# Model architecture
model:
  max_events: 243
  max_tokens_per_event: 128
  hidden_dim: 256
  num_layers: 6
  num_heads: 8
  dropout: 0.1
  time_vocab_size: 10  # 0-9 for discrete time
  time_dim: 3  # 3 digits for time

# Training
training:
  batch_size: 32
  epochs: 50
  learning_rate: 0.0001
  weight_decay: 0.01
  mask_ratio: 0.15  # BERT-style masking ratio
  save_every: 5
  exp_dir: "experiments/mdlm_base"

# Generation
generation:
  n_steps: 100  # Iterative refinement steps
  temperature: 1.0